//
//  Generated by the J2ObjC translator.  DO NOT EDIT!
//  source: ./memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
//

#include "J2ObjC_header.h"

#pragma push_macro("INCLUDE_ALL_OrgApacheLuceneIndexMemoryMemoryIndex")
#ifdef RESTRICT_OrgApacheLuceneIndexMemoryMemoryIndex
#define INCLUDE_ALL_OrgApacheLuceneIndexMemoryMemoryIndex 0
#else
#define INCLUDE_ALL_OrgApacheLuceneIndexMemoryMemoryIndex 1
#endif
#undef RESTRICT_OrgApacheLuceneIndexMemoryMemoryIndex

#if !defined (OrgApacheLuceneIndexMemoryMemoryIndex_) && (INCLUDE_ALL_OrgApacheLuceneIndexMemoryMemoryIndex || defined(INCLUDE_OrgApacheLuceneIndexMemoryMemoryIndex))
#define OrgApacheLuceneIndexMemoryMemoryIndex_

@class OrgApacheLuceneAnalysisAnalyzer;
@class OrgApacheLuceneAnalysisTokenStream;
@class OrgApacheLuceneSearchIndexSearcher;
@class OrgApacheLuceneSearchQuery;
@class OrgApacheLuceneSearchSimilaritiesSimilarity;
@protocol JavaUtilCollection;

/*!
 @brief High-performance single-document main memory Apache Lucene fulltext search index.
 <p>
 <b>Overview</b>
 <p>
 This class is a replacement/substitute for a large subset of
 <code>RAMDirectory</code> functionality. It is designed to
 enable maximum efficiency for on-the-fly matchmaking combining structured and 
 fuzzy fulltext search in realtime streaming applications such as Nux XQuery based XML 
 message queues, publish-subscribe systems for Blogs/newsfeeds, text chat, data acquisition and 
 distribution systems, application level routers, firewalls, classifiers, etc. 
 Rather than targeting fulltext search of infrequent queries over huge persistent 
 data archives (historic search), this class targets fulltext search of huge 
 numbers of queries over comparatively small transient realtime data (prospective 
 search). 
 For example as in 
 <pre class="prettyprint">
 float score = search(String text, Query query)
 
@endcode
 <p>
 Each instance can hold at most one Lucene "document", with a document containing
 zero or more "fields", each field having a name and a fulltext value. The
 fulltext value is tokenized (split and transformed) into zero or more index terms 
 (aka words) on <code>addField()</code>, according to the policy implemented by an
 Analyzer. For example, Lucene analyzers can split on whitespace, normalize to lower case
 for case insensitivity, ignore common terms with little discriminatory value such as "he", "in", "and" (stop
 words), reduce the terms to their natural linguistic root form such as "fishing"
 being reduced to "fish" (stemming), resolve synonyms/inflexions/thesauri 
 (upon indexing and/or querying), etc. For details, see
 <a target="_blank" href="http://today.java.net/pub/a/today/2003/07/30/LuceneIntro.html">Lucene Analyzer Intro</a>.
 <p>
 Arbitrary Lucene queries can be run against this class - see <a target="_blank" 
 href="/../queryparser/org/apache/lucene/queryparser/classic/package-summary.html#package_description">
 Lucene Query Syntax</a>
 as well as <a target="_blank" 
 href="http://today.java.net/pub/a/today/2003/11/07/QueryParserRules.html">Query Parser Rules</a>.
 Note that a Lucene query selects on the field names and associated (indexed) 
 tokenized terms, not on the original fulltext(s) - the latter are not stored 
 but rather thrown away immediately after tokenization.
 <p>
 For some interesting background information on search technology, see Bob Wyman's
 <a target="_blank" 
 href="http://bobwyman.pubsub.com/main/2005/05/mary_hodder_poi.html">Prospective Search</a>, 
 Jim Gray's
 <a target="_blank" href="http://www.acmqueue.org/modules.php?name=Content&pa=showpage&pid=293&page=4">
 A Call to Arms - Custom subscriptions</a>, and Tim Bray's
 <a target="_blank" 
 href="http://www.tbray.org/ongoing/When/200x/2003/07/30/OnSearchTOC">On Search, the Series</a>.
 <p>
 <b>Example Usage</b> 
 <br>
 <pre class="prettyprint">
 Analyzer analyzer = new SimpleAnalyzer(version);
 MemoryIndex index = new MemoryIndex();
 index.addField("content", "Readings about Salmons and other select Alaska fishing Manuals", analyzer);
 index.addField("author", "Tales of James", analyzer);
 QueryParser parser = new QueryParser(version, "content", analyzer);
 float score = index.search(parser.parse("+author:james +salmon~ +fish* manual~"));
 if (score &gt; 0.0f) {
 System.out.println("it's a match");
 } else {
 System.out.println("no match found");
 }
 System.out.println("indexData=" + index.toString());
 
@endcode
 <p>
 <b>Example XQuery Usage</b> 
 <pre class="prettyprint">
 (: An XQuery that finds all books authored by James that have something to do with "salmon fishing manuals", sorted by relevance :)
 declare namespace lucene = "java:nux.xom.pool.FullTextUtil";
 declare variable $query := "+salmon~ +fish* manual~"; (: any arbitrary Lucene query can go here :)
 for $book in /books/book[author="James" and lucene:match(abstract, $query) &gt; 0.0]
 let $score := lucene:match($book/abstract, $query)
 order by $score descending
 return $book
 
@endcode
 <p>
 <b>Thread safety guarantees</b>
 <p>
 MemoryIndex is not normally thread-safe for adds or queries.  However, queries
 are thread-safe after <code>freeze()</code> has been called.
 <p>
 <b>Performance Notes</b>
 <p>
 Internally there's a new data structure geared towards efficient indexing 
 and searching, plus the necessary support code to seamlessly plug into the Lucene 
 framework.
 <p>
 This class performs very well for very small texts (e.g. 10 chars) 
 as well as for large texts (e.g. 10 MB) and everything in between. 
 Typically, it is about 10-100 times faster than <code>RAMDirectory</code>.
 Note that <code>RAMDirectory</code> has particularly 
 large efficiency overheads for small to medium sized texts, both in time and space.
 Indexing a field with N tokens takes O(N) in the best case, and O(N logN) in the worst 
 case. Memory consumption is probably larger than for <code>RAMDirectory</code>.
 <p>
 Example throughput of many simple term queries over a single MemoryIndex: 
 ~500000 queries/sec on a MacBook Pro, jdk 1.5.0_06, server VM. 
 As always, your mileage may vary.
 <p>
 If you're curious about
 the whereabouts of bottlenecks, run java 1.5 with the non-perturbing '-server
 -agentlib:hprof=cpu=samples,depth=10' flags, then study the trace log and
 correlate its hotspot trailer with its call stack headers (see <a
 target="_blank"
 href="http://java.sun.com/developer/technicalArticles/Programming/HPROF.html">
 hprof tracing </a>).
 */
@interface OrgApacheLuceneIndexMemoryMemoryIndex : NSObject

#pragma mark Public

/*!
 @brief Constructs an empty instance that will not store offsets or payloads.
 */
- (instancetype)init;

/*!
 @brief Constructs an empty instance that can optionally store the start and end
 character offset of each token term in the text.
 This can be useful for
 highlighting of hit locations with the Lucene highlighter package.  But
 it will not store payloads; use another constructor for that.
 @param storeOffsets
 whether or not to store the start and end character offset of
 each token term in the text
 */
- (instancetype)initWithBoolean:(jboolean)storeOffsets;

/*!
 @brief Constructs an empty instance with the option of storing offsets and payloads.
 @param storeOffsets store term offsets at each position
 @param storePayloads store term payloads at each position
 */
- (instancetype)initWithBoolean:(jboolean)storeOffsets
                    withBoolean:(jboolean)storePayloads;

/*!
 @brief Convenience method; Tokenizes the given field text and adds the resulting
 terms to the index; Equivalent to adding an indexed non-keyword Lucene
 <code>org.apache.lucene.document.Field</code> that is tokenized, not stored,
 termVectorStored with positions (or termVectorStored with positions and offsets),
 @param fieldName
 a name to be associated with the text
 @param text
 the text to tokenize and index.
 @param analyzer
 the analyzer to use for tokenization
 */
- (void)addFieldWithNSString:(NSString *)fieldName
                withNSString:(NSString *)text
withOrgApacheLuceneAnalysisAnalyzer:(OrgApacheLuceneAnalysisAnalyzer *)analyzer;

/*!
 @brief Equivalent to <code>addField(fieldName, stream, 1.0f)</code>.
 @param fieldName
 a name to be associated with the text
 @param stream
 the token stream to retrieve tokens from
 */
- (void)addFieldWithNSString:(NSString *)fieldName
withOrgApacheLuceneAnalysisTokenStream:(OrgApacheLuceneAnalysisTokenStream *)stream;

/*!
 @brief Iterates over the given token stream and adds the resulting terms to the index;
 Equivalent to adding a tokenized, indexed, termVectorStored, unstored,
 Lucene <code>org.apache.lucene.document.Field</code>.
 Finally closes the token stream. Note that untokenized keywords can be added with this method via 
 <code>keywordTokenStream(Collection)</code>, the Lucene <code>KeywordTokenizer</code> or similar utilities.
 @param fieldName
 a name to be associated with the text
 @param stream
 the token stream to retrieve tokens from.
 @param boost
 the boost factor for hits for this field
 - seealso: org.apache.lucene.document.Field#setBoost(float)
 */
- (void)addFieldWithNSString:(NSString *)fieldName
withOrgApacheLuceneAnalysisTokenStream:(OrgApacheLuceneAnalysisTokenStream *)stream
                   withFloat:(jfloat)boost;

/*!
 @brief Iterates over the given token stream and adds the resulting terms to the index;
 Equivalent to adding a tokenized, indexed, termVectorStored, unstored,
 Lucene <code>org.apache.lucene.document.Field</code>.
 Finally closes the token stream. Note that untokenized keywords can be added with this method via
 <code>keywordTokenStream(Collection)</code>, the Lucene <code>KeywordTokenizer</code> or similar utilities.
 @param fieldName
 a name to be associated with the text
 @param stream
 the token stream to retrieve tokens from.
 @param boost
 the boost factor for hits for this field
 @param positionIncrementGap
 the position increment gap if fields with the same name are added more than once
 - seealso: org.apache.lucene.document.Field#setBoost(float)
 */
- (void)addFieldWithNSString:(NSString *)fieldName
withOrgApacheLuceneAnalysisTokenStream:(OrgApacheLuceneAnalysisTokenStream *)stream
                   withFloat:(jfloat)boost
                     withInt:(jint)positionIncrementGap;

/*!
 @brief Iterates over the given token stream and adds the resulting terms to the index;
 Equivalent to adding a tokenized, indexed, termVectorStored, unstored,
 Lucene <code>org.apache.lucene.document.Field</code>.
 Finally closes the token stream. Note that untokenized keywords can be added with this method via 
 <code>keywordTokenStream(Collection)</code>, the Lucene <code>KeywordTokenizer</code> or similar utilities.
 @param fieldName
 a name to be associated with the text
 @param tokenStream
 the token stream to retrieve tokens from. It's guaranteed to be closed no matter what.
 @param boost
 the boost factor for hits for this field
 @param positionIncrementGap
 the position increment gap if fields with the same name are added more than once
 @param offsetGap
 the offset gap if fields with the same name are added more than once
 - seealso: org.apache.lucene.document.Field#setBoost(float)
 */
- (void)addFieldWithNSString:(NSString *)fieldName
withOrgApacheLuceneAnalysisTokenStream:(OrgApacheLuceneAnalysisTokenStream *)tokenStream
                   withFloat:(jfloat)boost
                     withInt:(jint)positionIncrementGap
                     withInt:(jint)offsetGap;

/*!
 @brief Creates and returns a searcher that can be used to execute arbitrary
 Lucene queries and to collect the resulting query results as hits.
 @return a searcher
 */
- (OrgApacheLuceneSearchIndexSearcher *)createSearcher;

/*!
 @brief Prepares the MemoryIndex for querying in a non-lazy way.
 <p>
 After calling this you can query the MemoryIndex from multiple threads, but you
 cannot subsequently add new data.
 */
- (void)freeze;

/*!
 @brief Convenience method; Creates and returns a token stream that generates a
 token for each keyword in the given collection, "as is", without any
 transforming text analysis.
 The resulting token stream can be fed into
 <code>addField(String,TokenStream)</code>, perhaps wrapped into another
 <code>org.apache.lucene.analysis.TokenFilter</code>, as desired.
 @param keywords
 the keywords to generate tokens for
 @return the corresponding token stream
 */
- (OrgApacheLuceneAnalysisTokenStream *)keywordTokenStreamWithJavaUtilCollection:(id<JavaUtilCollection>)keywords;

/*!
 @brief Resets the <code>MemoryIndex</code> to its initial state and recycles all internal buffers.
 */
- (void)reset;

/*!
 @brief Convenience method that efficiently returns the relevance score by
 matching this index against the given Lucene query expression.
 @param query
 an arbitrary Lucene query to run against this index
 @return the relevance score of the matchmaking; A number in the range
 [0.0 .. 1.0], with 0.0 indicating no match. The higher the number
 the better the match.
 */
- (jfloat)searchWithOrgApacheLuceneSearchQuery:(OrgApacheLuceneSearchQuery *)query;

/*!
 @brief Set the Similarity to be used for calculating field norms
 */
- (void)setSimilarityWithOrgApacheLuceneSearchSimilaritiesSimilarity:(OrgApacheLuceneSearchSimilaritiesSimilarity *)similarity;

/*!
 @brief Returns a String representation of the index data for debugging purposes.
 @return the string representation
 */
- (NSString *)description;

#pragma mark Package-Private

/*!
 @brief Expert: This constructor accepts an upper limit for the number of bytes that should be reused if this instance is <code>reset()</code>.
 The payload storage, if used, is unaffected by maxReusuedBytes, however.
 @param storeOffsets <code>true</code> if offsets should be stored
 @param storePayloads <code>true</code> if payloads should be stored
 @param maxReusedBytes the number of bytes that should remain in the internal memory pools after <code>reset()</code> is called
 */
- (instancetype)initWithBoolean:(jboolean)storeOffsets
                    withBoolean:(jboolean)storePayloads
                       withLong:(jlong)maxReusedBytes;

@end

J2OBJC_EMPTY_STATIC_INIT(OrgApacheLuceneIndexMemoryMemoryIndex)

FOUNDATION_EXPORT void OrgApacheLuceneIndexMemoryMemoryIndex_init(OrgApacheLuceneIndexMemoryMemoryIndex *self);

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *new_OrgApacheLuceneIndexMemoryMemoryIndex_init() NS_RETURNS_RETAINED;

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *create_OrgApacheLuceneIndexMemoryMemoryIndex_init();

FOUNDATION_EXPORT void OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_(OrgApacheLuceneIndexMemoryMemoryIndex *self, jboolean storeOffsets);

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *new_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_(jboolean storeOffsets) NS_RETURNS_RETAINED;

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *create_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_(jboolean storeOffsets);

FOUNDATION_EXPORT void OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_(OrgApacheLuceneIndexMemoryMemoryIndex *self, jboolean storeOffsets, jboolean storePayloads);

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *new_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_(jboolean storeOffsets, jboolean storePayloads) NS_RETURNS_RETAINED;

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *create_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_(jboolean storeOffsets, jboolean storePayloads);

FOUNDATION_EXPORT void OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_withLong_(OrgApacheLuceneIndexMemoryMemoryIndex *self, jboolean storeOffsets, jboolean storePayloads, jlong maxReusedBytes);

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *new_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_withLong_(jboolean storeOffsets, jboolean storePayloads, jlong maxReusedBytes) NS_RETURNS_RETAINED;

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *create_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_withLong_(jboolean storeOffsets, jboolean storePayloads, jlong maxReusedBytes);

J2OBJC_TYPE_LITERAL_HEADER(OrgApacheLuceneIndexMemoryMemoryIndex)

#endif

#pragma pop_macro("INCLUDE_ALL_OrgApacheLuceneIndexMemoryMemoryIndex")
