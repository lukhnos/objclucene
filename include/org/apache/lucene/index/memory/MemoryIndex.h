//
//  Generated by the J2ObjC translator.  DO NOT EDIT!
//  source: ./memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
//

#include "J2ObjC_header.h"

#pragma push_macro("INCLUDE_ALL_OrgApacheLuceneIndexMemoryMemoryIndex")
#ifdef RESTRICT_OrgApacheLuceneIndexMemoryMemoryIndex
#define INCLUDE_ALL_OrgApacheLuceneIndexMemoryMemoryIndex 0
#else
#define INCLUDE_ALL_OrgApacheLuceneIndexMemoryMemoryIndex 1
#endif
#undef RESTRICT_OrgApacheLuceneIndexMemoryMemoryIndex

#if __has_feature(nullability)
#pragma clang diagnostic push
#pragma GCC diagnostic ignored "-Wnullability"
#pragma GCC diagnostic ignored "-Wnullability-completeness"
#endif

#if !defined (OrgApacheLuceneIndexMemoryMemoryIndex_) && (INCLUDE_ALL_OrgApacheLuceneIndexMemoryMemoryIndex || defined(INCLUDE_OrgApacheLuceneIndexMemoryMemoryIndex))
#define OrgApacheLuceneIndexMemoryMemoryIndex_

@class OrgApacheLuceneAnalysisAnalyzer;
@class OrgApacheLuceneAnalysisTokenStream;
@class OrgApacheLuceneSearchIndexSearcher;
@class OrgApacheLuceneSearchQuery;
@class OrgApacheLuceneSearchSimilaritiesSimilarity;
@protocol JavaUtilCollection;

/*!
 @brief High-performance single-document main memory Apache Lucene fulltext search index.
 <p>
  <b>Overview</b>
  <p>
  This class is a replacement/substitute for a large subset of 
 <code>RAMDirectory</code> functionality. It is designed to
  enable maximum efficiency for on-the-fly matchmaking combining structured and 
  fuzzy fulltext search in realtime streaming applications such as Nux XQuery based XML 
  message queues, publish-subscribe systems for Blogs/newsfeeds, text chat, data acquisition and 
  distribution systems, application level routers, firewalls, classifiers, etc. 
  Rather than targeting fulltext search of infrequent queries over huge persistent 
  data archives (historic search), this class targets fulltext search of huge 
  numbers of queries over comparatively small transient realtime data (prospective 
  search). 
  For example as in  
 <pre class="prettyprint">
  float score = search(String text, Query query) 
 
@endcode
  <p>
  Each instance can hold at most one Lucene "document", with a document containing
  zero or more "fields", each field having a name and a fulltext value. The
  fulltext value is tokenized (split and transformed) into zero or more index terms 
  (aka words) on <code>addField()</code>, according to the policy implemented by an
  Analyzer. For example, Lucene analyzers can split on whitespace, normalize to lower case
  for case insensitivity, ignore common terms with little discriminatory value such as "he", "in", "and" (stop
  words), reduce the terms to their natural linguistic root form such as "fishing"
  being reduced to "fish" (stemming), resolve synonyms/inflexions/thesauri 
  (upon indexing and/or querying), etc. For details, see 
 <a target="_blank" href="http://today.java.net/pub/a/today/2003/07/30/LuceneIntro.html">Lucene Analyzer Intro</a>.
  <p>
  Arbitrary Lucene queries can be run against this class - see <a target="_blank" href="{@@docRoot}/../queryparser/org/apache/lucene/queryparser/classic/package-summary.html#package_description">
  Lucene Query Syntax</a>
  as well as <a target="_blank" href="http://today.java.net/pub/a/today/2003/11/07/QueryParserRules.html">
 Query Parser Rules</a>.
  Note that a Lucene query selects on the field names and associated (indexed) 
  tokenized terms, not on the original fulltext(s) - the latter are not stored 
  but rather thrown away immediately after tokenization. 
 <p>
  For some interesting background information on search technology, see Bob Wyman's 
 <a target="_blank" href="http://bobwyman.pubsub.com/main/2005/05/mary_hodder_poi.html">
 Prospective Search</a>, 
  Jim Gray's 
 <a target="_blank" href="http://www.acmqueue.org/modules.php?name=Content&pa=showpage&pid=293&page=4">
  A Call to Arms - Custom subscriptions</a>, and Tim Bray's 
 <a target="_blank" href="http://www.tbray.org/ongoing/When/200x/2003/07/30/OnSearchTOC">
 On Search, the Series</a>.
   
 <p>
  <b>Example Usage</b>  
 <br>
  <pre class="prettyprint">
  Analyzer analyzer = new SimpleAnalyzer(version);
  MemoryIndex index = new MemoryIndex();
  index.addField("content", "Readings about Salmons and other select Alaska fishing Manuals", analyzer);
  index.addField("author", "Tales of James", analyzer);
  QueryParser parser = new QueryParser(version, "content", analyzer);
  float score = index.search(parser.parse("+author:james +salmon~ +fish* manual~"));
  if (score &gt; 0.0f) {
      System.out.println("it's a match");
  } else {
      System.out.println("no match found");
  }
  System.out.println("indexData=" + index.toString()); 
 
@endcode
   
 <p>
  <b>Example XQuery Usage</b>   
 <pre class="prettyprint">
  (: An XQuery that finds all books authored by James that have something to do with "salmon fishing manuals", sorted by relevance :)
  declare namespace lucene = "java:nux.xom.pool.FullTextUtil";
  declare variable $query := "+salmon~ +fish* manual~"; (: any arbitrary Lucene query can go here :) 
  for $book in /books/book[author="James" and lucene:match(abstract, $query) &gt; 0.0]
  let $score := lucene:match($book/abstract, $query)
  order by $score descending
  return $book 
 
@endcode
   
 <p>
  <b>Thread safety guarantees</b>
  <p>
  MemoryIndex is not normally thread-safe for adds or queries.  However, queries
  are thread-safe after <code>freeze()</code> has been called. 
 <p>
  <b>Performance Notes</b>
  <p>
  Internally there's a new data structure geared towards efficient indexing 
  and searching, plus the necessary support code to seamlessly plug into the Lucene 
  framework. 
 <p>
  This class performs very well for very small texts (e.g. 10 chars) 
  as well as for large texts (e.g. 10 MB) and everything in between. 
  Typically, it is about 10-100 times faster than <code>RAMDirectory</code>.
  Note that <code>RAMDirectory</code> has particularly 
  large efficiency overheads for small to medium sized texts, both in time and space.
  Indexing a field with N tokens takes O(N) in the best case, and O(N logN) in the worst 
  case. Memory consumption is probably larger than for <code>RAMDirectory</code>.
  <p>
  Example throughput of many simple term queries over a single MemoryIndex: 
  ~500000 queries/sec on a MacBook Pro, jdk 1.5.0_06, server VM. 
  As always, your mileage may vary. 
 <p>
  If you're curious about
  the whereabouts of bottlenecks, run java 1.5 with the non-perturbing '-server
  -agentlib:hprof=cpu=samples,depth=10' flags, then study the trace log and
  correlate its hotspot trailer with its call stack headers (see <a target="_blank" href="http://java.sun.com/developer/technicalArticles/Programming/HPROF.html">
  hprof tracing </a>).
 */
@interface OrgApacheLuceneIndexMemoryMemoryIndex : NSObject

#pragma mark Public

/*!
 @brief Constructs an empty instance that will not store offsets or payloads.
 */
- (instancetype __nonnull)init;

/*!
 @brief Constructs an empty instance that can optionally store the start and end
  character offset of each token term in the text.This can be useful for
  highlighting of hit locations with the Lucene highlighter package.
 But
  it will not store payloads; use another constructor for that.
 @param storeOffsets whether or not to store the start and end character offset of
              each token term in the text
 */
- (instancetype __nonnull)initWithBoolean:(jboolean)storeOffsets;

/*!
 @brief Constructs an empty instance with the option of storing offsets and payloads.
 @param storeOffsets store term offsets at each position
 @param storePayloads store term payloads at each position
 */
- (instancetype __nonnull)initWithBoolean:(jboolean)storeOffsets
                              withBoolean:(jboolean)storePayloads;

/*!
 @brief Convenience method; Tokenizes the given field text and adds the resulting
  terms to the index; Equivalent to adding an indexed non-keyword Lucene 
 <code>org.apache.lucene.document.Field</code> that is tokenized, not stored,
  termVectorStored with positions (or termVectorStored with positions and offsets),
 @param fieldName a name to be associated with the text
 @param text the text to tokenize and index.
 @param analyzer the analyzer to use for tokenization
 */
- (void)addFieldWithNSString:(NSString *)fieldName
                withNSString:(NSString *)text
withOrgApacheLuceneAnalysisAnalyzer:(OrgApacheLuceneAnalysisAnalyzer *)analyzer;

/*!
 @brief Equivalent to <code>addField(fieldName, stream, 1.0f)</code>.
 @param fieldName a name to be associated with the text
 @param stream the token stream to retrieve tokens from
 */
- (void)addFieldWithNSString:(NSString *)fieldName
withOrgApacheLuceneAnalysisTokenStream:(OrgApacheLuceneAnalysisTokenStream *)stream;

/*!
 @brief Iterates over the given token stream and adds the resulting terms to the index;
  Equivalent to adding a tokenized, indexed, termVectorStored, unstored,
  Lucene <code>org.apache.lucene.document.Field</code>.
 Finally closes the token stream. Note that untokenized keywords can be added with this method via  
 <code>keywordTokenStream(Collection)</code>, the Lucene <code>KeywordTokenizer</code> or similar utilities.
 @param fieldName a name to be associated with the text
 @param stream the token stream to retrieve tokens from.
 @param boost the boost factor for hits for this field
 - seealso: org.apache.lucene.document.Field#setBoost(float)
 */
- (void)addFieldWithNSString:(NSString *)fieldName
withOrgApacheLuceneAnalysisTokenStream:(OrgApacheLuceneAnalysisTokenStream *)stream
                   withFloat:(jfloat)boost;

/*!
 @brief Iterates over the given token stream and adds the resulting terms to the index;
  Equivalent to adding a tokenized, indexed, termVectorStored, unstored,
  Lucene <code>org.apache.lucene.document.Field</code>.
 Finally closes the token stream. Note that untokenized keywords can be added with this method via 
 <code>keywordTokenStream(Collection)</code>, the Lucene <code>KeywordTokenizer</code> or similar utilities.
 @param fieldName a name to be associated with the text
 @param stream the token stream to retrieve tokens from.
 @param boost the boost factor for hits for this field
 @param positionIncrementGap the position increment gap if fields with the same name are added more than once
 - seealso: org.apache.lucene.document.Field#setBoost(float)
 */
- (void)addFieldWithNSString:(NSString *)fieldName
withOrgApacheLuceneAnalysisTokenStream:(OrgApacheLuceneAnalysisTokenStream *)stream
                   withFloat:(jfloat)boost
                     withInt:(jint)positionIncrementGap;

/*!
 @brief Iterates over the given token stream and adds the resulting terms to the index;
  Equivalent to adding a tokenized, indexed, termVectorStored, unstored,
  Lucene <code>org.apache.lucene.document.Field</code>.
 Finally closes the token stream. Note that untokenized keywords can be added with this method via  
 <code>keywordTokenStream(Collection)</code>, the Lucene <code>KeywordTokenizer</code> or similar utilities.
 @param fieldName a name to be associated with the text
 @param tokenStream the token stream to retrieve tokens from. It's guaranteed to be closed no matter what.
 @param boost the boost factor for hits for this field
 @param positionIncrementGap the position increment gap if fields with the same name are added more than once
 @param offsetGap the offset gap if fields with the same name are added more than once
 - seealso: org.apache.lucene.document.Field#setBoost(float)
 */
- (void)addFieldWithNSString:(NSString *)fieldName
withOrgApacheLuceneAnalysisTokenStream:(OrgApacheLuceneAnalysisTokenStream *)tokenStream
                   withFloat:(jfloat)boost
                     withInt:(jint)positionIncrementGap
                     withInt:(jint)offsetGap;

/*!
 @brief Creates and returns a searcher that can be used to execute arbitrary
  Lucene queries and to collect the resulting query results as hits.
 @return a searcher
 */
- (OrgApacheLuceneSearchIndexSearcher *)createSearcher;

/*!
 @brief Prepares the MemoryIndex for querying in a non-lazy way.
 <p>
  After calling this you can query the MemoryIndex from multiple threads, but you
  cannot subsequently add new data.
 */
- (void)freeze;

/*!
 @brief Convenience method; Creates and returns a token stream that generates a
  token for each keyword in the given collection, "as is", without any
  transforming text analysis.The resulting token stream can be fed into 
 <code>addField(String, TokenStream)</code>, perhaps wrapped into another 
 <code>org.apache.lucene.analysis.TokenFilter</code>, as desired.
 @param keywords the keywords to generate tokens for
 @return the corresponding token stream
 */
- (OrgApacheLuceneAnalysisTokenStream *)keywordTokenStreamWithJavaUtilCollection:(id<JavaUtilCollection>)keywords;

/*!
 @brief Resets the <code>MemoryIndex</code> to its initial state and recycles all internal buffers.
 */
- (void)reset;

/*!
 @brief Convenience method that efficiently returns the relevance score by
  matching this index against the given Lucene query expression.
 @param query an arbitrary Lucene query to run against this index
 @return the relevance score of the matchmaking; A number in the range
          [0.0 .. 1.0], with 0.0 indicating no match. The higher the number
          the better the match.
 */
- (jfloat)searchWithOrgApacheLuceneSearchQuery:(OrgApacheLuceneSearchQuery *)query;

/*!
 @brief Set the Similarity to be used for calculating field norms
 */
- (void)setSimilarityWithOrgApacheLuceneSearchSimilaritiesSimilarity:(OrgApacheLuceneSearchSimilaritiesSimilarity *)similarity;

/*!
 @brief Returns a String representation of the index data for debugging purposes.
 @return the string representation
 */
- (NSString *)description;

#pragma mark Package-Private

/*!
 @brief Expert: This constructor accepts an upper limit for the number of bytes that should be reused if this instance is <code>reset()</code>.
 The payload storage, if used, is unaffected by maxReusuedBytes, however.
 @param storeOffsets <code> true </code>  if offsets should be stored
 @param storePayloads <code> true </code>  if payloads should be stored
 @param maxReusedBytes the number of bytes that should remain in the internal memory pools after <code>reset()</code>  is called
 */
- (instancetype __nonnull)initWithBoolean:(jboolean)storeOffsets
                              withBoolean:(jboolean)storePayloads
                                 withLong:(jlong)maxReusedBytes;

@end

J2OBJC_EMPTY_STATIC_INIT(OrgApacheLuceneIndexMemoryMemoryIndex)

FOUNDATION_EXPORT void OrgApacheLuceneIndexMemoryMemoryIndex_init(OrgApacheLuceneIndexMemoryMemoryIndex *self);

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *new_OrgApacheLuceneIndexMemoryMemoryIndex_init(void) NS_RETURNS_RETAINED;

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *create_OrgApacheLuceneIndexMemoryMemoryIndex_init(void);

FOUNDATION_EXPORT void OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_(OrgApacheLuceneIndexMemoryMemoryIndex *self, jboolean storeOffsets);

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *new_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_(jboolean storeOffsets) NS_RETURNS_RETAINED;

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *create_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_(jboolean storeOffsets);

FOUNDATION_EXPORT void OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_(OrgApacheLuceneIndexMemoryMemoryIndex *self, jboolean storeOffsets, jboolean storePayloads);

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *new_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_(jboolean storeOffsets, jboolean storePayloads) NS_RETURNS_RETAINED;

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *create_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_(jboolean storeOffsets, jboolean storePayloads);

FOUNDATION_EXPORT void OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_withLong_(OrgApacheLuceneIndexMemoryMemoryIndex *self, jboolean storeOffsets, jboolean storePayloads, jlong maxReusedBytes);

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *new_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_withLong_(jboolean storeOffsets, jboolean storePayloads, jlong maxReusedBytes) NS_RETURNS_RETAINED;

FOUNDATION_EXPORT OrgApacheLuceneIndexMemoryMemoryIndex *create_OrgApacheLuceneIndexMemoryMemoryIndex_initWithBoolean_withBoolean_withLong_(jboolean storeOffsets, jboolean storePayloads, jlong maxReusedBytes);

J2OBJC_TYPE_LITERAL_HEADER(OrgApacheLuceneIndexMemoryMemoryIndex)

#endif


#if __has_feature(nullability)
#pragma clang diagnostic pop
#endif
#pragma pop_macro("INCLUDE_ALL_OrgApacheLuceneIndexMemoryMemoryIndex")
